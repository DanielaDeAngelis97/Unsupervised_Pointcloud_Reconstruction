{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DGCNN-AE_Encoder512.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StefanoBergia/Unsupervised_Pointcloud_Reconstruction/blob/main/DGCNN_AE_Encoder512.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7txbjM-ng21"
      },
      "source": [
        "# AIML20 Project - DGCNN AE\n",
        "\n",
        "> Blocco con rientro\n",
        "\n",
        "\n",
        "### Assistant: Antonio Alliegro, antonio.alliegro at polito dot it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZQE7t2ercoh",
        "outputId": "6148cac2-9ef5-421b-92f0-3df18b3e1691"
      },
      "source": [
        "!pip install plotly.express"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting plotly.express\n",
            "  Downloading https://files.pythonhosted.org/packages/d4/d6/8a2906f51e073a4be80cab35cfa10e7a34853e60f3ed5304ac470852a08d/plotly_express-0.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from plotly.express) (1.19.5)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.6/dist-packages (from plotly.express) (0.5.1)\n",
            "Requirement already satisfied: pandas>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from plotly.express) (1.1.5)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from plotly.express) (0.10.2)\n",
            "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.6/dist-packages (from plotly.express) (1.4.1)\n",
            "Requirement already satisfied: plotly>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from plotly.express) (4.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5->plotly.express) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.0->plotly.express) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.0->plotly.express) (2.8.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.1.0->plotly.express) (1.3.3)\n",
            "Installing collected packages: plotly.express\n",
            "Successfully installed plotly.express\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdMzmw6mJ16k",
        "outputId": "ff4478fd-f606-48aa-fe63-8f940c652555"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from google.colab import drive\n",
        "import torch.utils.data as data\n",
        "import os\n",
        "import json\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from tqdm import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWnlTtquZSa2"
      },
      "source": [
        "## Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j16xhIKxZXlf"
      },
      "source": [
        "class ShapeNetDataset(data.Dataset):\r\n",
        "    def __init__(self,\r\n",
        "                 root,\r\n",
        "                 npoints=1024,      #previously 2500\r\n",
        "                 classification=False,\r\n",
        "                 class_choice=None,\r\n",
        "                 split='train',\r\n",
        "                 data_augmentation=False):\r\n",
        "        self.npoints = npoints                                              #number of poits to random sample\r\n",
        "        self.root = root                                                    #root folder for the dataset\r\n",
        "        self.catfile = os.path.join(self.root, 'synsetoffset2category.txt') #contains the mapping between class name and folder name\r\n",
        "        self.cat = {}                                                       #dictionary that maps class name and folders\r\n",
        "        self.data_augmentation = data_augmentation                          #we don't use it\r\n",
        "        self.classification = classification                                #flag to decide between classification and segmentation\r\n",
        "        self.seg_classes = {}                                               #maps for each class name the number of segment possible for that class\r\n",
        "        self.meta = {}                                                      #maps each class to the list of path of the pointclouds\r\n",
        "\r\n",
        "\r\n",
        "        with open(self.catfile, 'r') as f:                                  #initialize self.cat to map classname and folder\r\n",
        "            for line in f:\r\n",
        "                ls = line.strip().split()\r\n",
        "                self.cat[ls[0]] = ls[1]\r\n",
        "  \r\n",
        "        if not class_choice is None:                                        #filters only the classes we are interested in\r\n",
        "            self.cat = {k: v for k, v in self.cat.items() if k in class_choice}\r\n",
        "\r\n",
        "        self.id2cat = {v: k for k, v in self.cat.items()}                   #reverse mapping between classes and folder\r\n",
        "\r\n",
        "        splitfile = os.path.join(self.root, 'train_test_split', 'shuffled_{}_file_list.json'.format(split)) #opens the train/validation/test file\r\n",
        "        filelist = json.load(open(splitfile, 'r'))\r\n",
        "        for item in self.cat:           #init class label\r\n",
        "            self.meta[item] = []        \r\n",
        "\r\n",
        "        for file in filelist:\r\n",
        "            _, category, uuid = file.split('/')\r\n",
        "            if category in self.cat.values():\r\n",
        "                self.meta[self.id2cat[category]].append((os.path.join(self.root, category, 'points', uuid+'.pts'),  #appends path for pointcloud\r\n",
        "                                        os.path.join(self.root, category, 'points_label', uuid+'.seg')))            #appends path for segmentation of points\r\n",
        "\r\n",
        "        self.datapath = []\r\n",
        "        for item in self.cat:\r\n",
        "            for fn in self.meta[item]:\r\n",
        "                self.datapath.append((item, fn[0], fn[1]))          #transform meta in an array to be used with an integer index in getitem\r\n",
        "\r\n",
        "        self.classes = dict(zip(sorted(self.cat), range(len(self.cat))))  #create a dictionary with key=category value=id between 0 and number of categories\r\n",
        "        with open(os.path.join(self.root,'num_seg_classes.txt'), 'r') as f:\r\n",
        "            for line in f:\r\n",
        "                ls = line.strip().split()\r\n",
        "                self.seg_classes[ls[0]] = int(ls[1])      #set the number of segmentation part for each class\r\n",
        "        self.num_seg_classes = self.seg_classes[list(self.cat.keys())[0]]\r\n",
        "\r\n",
        "\r\n",
        "    def __getitem__(self, index):\r\n",
        "        fn = self.datapath[index]                         #gets an entry in datapath (classname pointcloud_path segment_path)\r\n",
        "        cls = self.classes[self.datapath[index][0]]       #gets class internal id\r\n",
        "        point_set = np.loadtxt(fn[1]).astype(np.float32)  #reads the pointcloud file and stores it  in a matrix nx3 (2 dimensions)\r\n",
        "        seg = np.loadtxt(fn[2]).astype(np.int64)          #reads the segmentation \r\n",
        "        \r\n",
        "        choice = np.random.choice(len(seg), self.npoints, replace=True)   #random sampling (default 1024 points)\r\n",
        "        point_set = point_set[choice, :]\r\n",
        "\r\n",
        "        point_set = point_set - np.expand_dims(np.mean(point_set, axis = 0), 0) #center, subtract the mean of each coordinate to each point\r\n",
        "        dist = np.max(np.sqrt(np.sum(point_set ** 2, axis = 1)),0)              #for each point conpute it's distance with respect to the origin anc take the maximum\r\n",
        "        point_set = point_set / dist                                            #scale to obtain maximum distance 1\r\n",
        "\r\n",
        "        if self.data_augmentation:\r\n",
        "            theta = np.random.uniform(0,np.pi*2)\r\n",
        "            rotation_matrix = np.array([[np.cos(theta), -np.sin(theta)],[np.sin(theta), np.cos(theta)]])\r\n",
        "            point_set[:,[0,2]] = point_set[:,[0,2]].dot(rotation_matrix) # random rotation\r\n",
        "            point_set += np.random.normal(0, 0.02, size=point_set.shape) # random jitter\r\n",
        "\r\n",
        "        seg = seg[choice]                             #random sampling for segment part \r\n",
        "\r\n",
        "        point_set = torch.from_numpy(point_set)                   #create pythorch tensor for pointcloud\r\n",
        "        seg = torch.from_numpy(seg)                               #create pythorch tensor for segmentation part\r\n",
        "        cls = torch.from_numpy(np.array([cls]).astype(np.int64))  #create pythorch tensor for classes id\r\n",
        "\r\n",
        "        if self.classification:\r\n",
        "            return point_set, cls\r\n",
        "        else:\r\n",
        "            return point_set, seg\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.datapath)     #return the number of pointcloud\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ2jcNt8KfQW"
      },
      "source": [
        "## DGCN Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPULYc5sK9E9"
      },
      "source": [
        "### Edge Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h08XVSoRJmQ6"
      },
      "source": [
        "def knn(x, k):\r\n",
        "    inner = -2*torch.matmul(x.transpose(2, 1), x)       #innser.size()-> [batchsize,npoints,npoints]\r\n",
        "    xx = torch.sum(x**2, dim=1, keepdim=True)          #distanza rispetto all'origine  #eleva ogni coordinata al quadrato e poi somma le 3 coordinate per ogni punto -> [batchsize,nfeature (3),npoints]->[batchsize,1,nponts]\r\n",
        "\r\n",
        "    pairwise_distance = -xx - inner - xx.transpose(2, 1) #[batchsize,npoints,npoints] distanza ogni punto con tutti gli altri\r\n",
        "\r\n",
        "    idx = pairwise_distance.topk(k=k, dim=-1)[1]   # (batch_size, num_points, k) ->  \r\n",
        "    return idx\r\n",
        "\r\n",
        "#riceve una singola pointcloud\r\n",
        "def knn2(x,k):\r\n",
        "    x=x.transpose(1,0)\r\n",
        "    x_norm = (x**2).sum(1).view(-1, 1)\r\n",
        "    y_norm = x_norm.view(1, -1)\r\n",
        "    dist = -x_norm - y_norm + 2.0 * torch.mm(x, torch.transpose(x, 0, 1))\r\n",
        "    idx = dist.topk(k=k, dim=-1)[1]   # (batch_size, num_points, k) ->  \r\n",
        "    return idx\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def get_graph_feature(x, k=20, idx=None):\r\n",
        "    batch_size = x.size(0)\r\n",
        "    num_points = x.size(2)\r\n",
        "    x = x.view(batch_size, -1, num_points)\r\n",
        "    device = torch.device('cuda')\r\n",
        "\r\n",
        "    v=1###############################change this parameter to use knn2\r\n",
        "    if idx is None:\r\n",
        "        if v==1:\r\n",
        "          idx = knn(x, k=k)   # (batch_size, num_points, k)\r\n",
        "        else:\r\n",
        "          #mia versione dentro la if\r\n",
        "          idx=torch.zeros([batch_size,num_points, k], dtype=torch.int32,device=device)\r\n",
        "          for i in range(0,batch_size):\r\n",
        "            idx[i,:,:]=knn2(x[i,:,:],k)\r\n",
        "        \r\n",
        "\r\n",
        "        \r\n",
        "\r\n",
        "\r\n",
        "    idx_base = torch.arange(0, batch_size, device=device).view(-1, 1, 1)*num_points #[batchsize,1,1] containing [[[0]],[[1*num_points]],..[[batchsize-1*numpoints]]]\r\n",
        "\r\n",
        "    idx = idx + idx_base        #somma ad ogni matrice di distanze (una per ogni batchsize) un offset corripondente al numero punti*inice batch\r\n",
        "\r\n",
        "    idx = idx.view(-1)      #concatena tutto in un unico array\r\n",
        " \r\n",
        "    _, num_dims, _ = x.size()\r\n",
        "\r\n",
        "    x = x.transpose(2, 1).contiguous()   # (batch_size, num_points, num_dims)  -> (batch_size*num_points, num_dims) #   batch_size * num_points * k + range(0, batch_size*num_points)\r\n",
        "    feature = x.view(batch_size*num_points, -1)[idx, :]   #associa ad ogni punto i k punti più vicini calcolati con knn i cui indici sono in idx, l'offset calcolato in preceenza serve per far si che punti di batch diversi non si influenzino a vicenda\r\n",
        "    feature = feature.view(batch_size, num_points, k, num_dims) \r\n",
        "    x = x.view(batch_size, num_points, 1, num_dims).repeat(1, 1, k, 1)  #\r\n",
        "    \r\n",
        "    feature = torch.cat((feature-x, x), dim=3).permute(0, 3, 1, 2).contiguous() #funzione h (theta*(xi-xj )+(fi)xi)\r\n",
        "  \r\n",
        "    return feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hSmeG-RJzAv"
      },
      "source": [
        "### DGCN Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLQz-UOpJ-yj"
      },
      "source": [
        "class DGCNN(nn.Module):\r\n",
        "    def __init__(self, emb_dims=1024,k=20,dropout=0.5, output_channels=1024):\r\n",
        "        super(DGCNN, self).__init__()\r\n",
        "        self.k = k\r\n",
        "        \r\n",
        "        self.bn1 = nn.BatchNorm2d(64)\r\n",
        "        self.bn2 = nn.BatchNorm2d(64)\r\n",
        "        self.bn3 = nn.BatchNorm2d(128)\r\n",
        "        self.bn4 = nn.BatchNorm2d(256)\r\n",
        "        self.bn5 = nn.BatchNorm1d(emb_dims)\r\n",
        "\r\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(6, 64, kernel_size=1, bias=False),\r\n",
        "                                   self.bn1,\r\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\r\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(64*2, 64, kernel_size=1, bias=False),\r\n",
        "                                   self.bn2,\r\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\r\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(64*2, 128, kernel_size=1, bias=False),\r\n",
        "                                   self.bn3,\r\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\r\n",
        "        self.conv4 = nn.Sequential(nn.Conv2d(128*2, 256, kernel_size=1, bias=False),\r\n",
        "                                   self.bn4,\r\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\r\n",
        "        self.conv5 = nn.Sequential(nn.Conv1d(512, emb_dims, kernel_size=1, bias=False),\r\n",
        "                                   self.bn5,\r\n",
        "                                   nn.LeakyReLU(negative_slope=0.2))\r\n",
        "        \r\n",
        "        self.linear3 = nn.Linear(emb_dims*2, output_channels)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        batch_size = x.size(0)\r\n",
        "        x = get_graph_feature(x, k=self.k)\r\n",
        "        x = self.conv1(x)\r\n",
        "        x1 = x.max(dim=-1, keepdim=False)[0]\r\n",
        "\r\n",
        "        x = get_graph_feature(x1, k=self.k)\r\n",
        "        x = self.conv2(x)\r\n",
        "        x2 = x.max(dim=-1, keepdim=False)[0]\r\n",
        "\r\n",
        "        x = get_graph_feature(x2, k=self.k)\r\n",
        "        x = self.conv3(x)\r\n",
        "        x3 = x.max(dim=-1, keepdim=False)[0]\r\n",
        "\r\n",
        "\r\n",
        "        x = get_graph_feature(x3, k=self.k)\r\n",
        "        x = self.conv4(x)\r\n",
        "        x4 = x.max(dim=-1, keepdim=False)[0]\r\n",
        "\r\n",
        "\r\n",
        "        x = torch.cat((x1, x2, x3, x4), dim=1)\r\n",
        "\r\n",
        "        x = self.conv5(x)\r\n",
        "\r\n",
        "        x1 = F.adaptive_max_pool1d(x, 1).view(batch_size, -1)\r\n",
        "        return x1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFheDJG0O5v4"
      },
      "source": [
        "#### DGCN AutoEncoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8Y5hI0KO5C3"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  ''' Just a lightweight Fully Connected decoder:\n",
        "  '''\n",
        "\n",
        "  def __init__(self, num_points = 2048):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.num_points = num_points\n",
        "        self.fc1 = nn.Linear(512, 1024)\n",
        "        self.fc2 = nn.Linear(1024, self.num_points * 3)\n",
        "        self.th = nn.Tanh()\n",
        "\n",
        "  def forward(self, x):\n",
        "      batchsize = x.size()[0]\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = self.th(self.fc2(x))\n",
        "      x = x.view(batchsize, 3, self.num_points)\n",
        "      return x\n",
        "\n",
        "\n",
        "class DGCNN_AutoEncoder(nn.Module):\n",
        "\n",
        "  def __init__(self, k=20,num_points=1024, feature_transform=False):\n",
        "    super(DGCNN_AutoEncoder, self).__init__()\n",
        "    print(\"DGCN AE Init - num_points (# generated): %d\" % num_points)\n",
        "\n",
        "    # Encoder Definition\n",
        "    self.encoder = torch.nn.Sequential(\n",
        "        DGCNN(k=k),\n",
        "        nn.Linear(1024, 512),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.ReLU(), \n",
        "        nn.Linear(512, 512),)\n",
        "    \n",
        "    # Decoder Definition\n",
        "    self.decoder = Decoder(num_points=num_points)\n",
        "\n",
        "  def forward(self, x):\n",
        "    BS, N, dim = x.size()\n",
        "    assert dim == 3, \"Fail: expecting 3 (x-y-z) as last tensor dimension!\"\n",
        "\n",
        "    # Refactoring batch for 'PointNetfeat' processing\n",
        "    x = x.permute(0, 2, 1)  # [BS, N, 3] => [BS, 3, N]\n",
        "\n",
        "    # Encoding\n",
        "    code = self.encoder(x)  # [BS, 3, N] => [BS, 100]\n",
        "\n",
        "    # Decoding\n",
        "    decoded = self.decoder(code)  # [BS, 3, num_points]\n",
        "\n",
        "    # Reshaping decoded output before returning..\n",
        "    decoded = decoded.permute(0,2,1)  # [BS, 3, num_points] => [BS, num_points, 3]\n",
        "\n",
        "    return decoded\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wueb5wZlYFbe",
        "outputId": "6ef09505-7595-4873-978c-f36be8fda008"
      },
      "source": [
        "batch_size = 32\n",
        "input_points = 1024\n",
        "\n",
        "# Instantiate a fake batch of point clouds\n",
        "points = torch.rand(batch_size, input_points, 3)\n",
        "print(\"Input points: \", points.size())\n",
        "# Instantiate the AE\n",
        "DGCNN_AE = DGCNN_AutoEncoder(num_points=input_points)\n",
        "\n",
        "# Move everything (data + model) to GPU\n",
        "assert torch.cuda.device_count() > 0, \"Fail: No GPU device detected\"\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "points = points.to(device)\n",
        "DGCNN_AE = DGCNN_AE.to(device) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input points:  torch.Size([32, 1024, 3])\n",
            "DGCN AE Init - num_points (# generated): 1024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdBUxA8vY10j",
        "outputId": "69bc05ab-6666-400c-af59-18d8b8536eef"
      },
      "source": [
        "# try AE forward\n",
        "print(points.size())\n",
        "decoded = DGCNN_AE(points)\n",
        "print(\"Decoded output: \", decoded.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 1024, 3])\n",
            "Decoded output:  torch.Size([32, 1024, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsSW-N5abNlu"
      },
      "source": [
        "## Loss Function - Chamfer\n",
        "Given the Original Point Cloud (PC) X and the decoded output Y we need a way to penalize the predicted/decoded w.r.t. the original PC X.<br>\n",
        "Standard MSE (Mean Squared Error) can't work cause both input and output are unordered sets of xyz-points.<br>\n",
        "Think at PCs as vectors of xyz-points, the order of each of the points is absolutely meaningless.\n",
        "Thus meaning that, since the lack of ordering for both input and decoded sets, you cannot simply compute the euclidean distance between the i-th element of the input tensor X and the i-th one of the decoded tensor Y.<br>\n",
        "We'll use the Chamfer Distance as training loss to keep the generated/decoded points close to original/(not encoded) points.\n",
        "The Chamfer Distance is not actually a distance but a pseudo-distance (dist(A,B) != dist(B,A)).<br>\n",
        "Let's consider the two sets X and Y. For each point in X we'll compute the euclidean distance to the nearest in the Y set. The same in the opposite direction, given each point of Y we'll compute the distance to the nearest in the X set. By doing so we're not making any assumption on the ordering of the X and Y sets.<br>\n",
        "The final loss will be the sum of two equally weighted contribution:\n",
        "1.   AVG_Y2X - Average of all nearest-dist Y->X: for each point in Y consider the distance to the nearest in X\n",
        "2.   AVG_X2Y - Average of all nearest-dist X->Y: same as 1. but opposite\n",
        "\n",
        "Thus:\n",
        "\n",
        "> CD_Loss = cd_weight * ( 0.5 * AVG_Y2X + 0.5 * AVG_X2Y )\n",
        "\n",
        "Where 'cd_weight' is a loss weight term that you should cross-validate. Hint: try with cd_weight=100!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qx_MvI4bNEz"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Simple Chamfer Distance / Loss implementation\n",
        "# Implementation from https://github.com/zztianzz/PF-Net-Point-Fractal-Network/blob/master/utils.py\n",
        "# CVPR2020 Paper PF-Net: Point Fractal Network for 3D Point Cloud Completion.\n",
        "\n",
        "def array2samples_distance(array1, array2):\n",
        "    \"\"\"\n",
        "    arguments: \n",
        "        array1: the array, size: (num_point, num_feature)\n",
        "        array2: the samples, size: (num_point, num_feature)\n",
        "    returns:\n",
        "        distances: each entry is the distance from a sample to array1 \n",
        "    \"\"\"\n",
        "    num_point1, num_features1 = array1.shape\n",
        "    num_point2, num_features2 = array2.shape\n",
        "    expanded_array1 = array1.repeat(num_point2, 1)\n",
        "    expanded_array2 = torch.reshape(\n",
        "            torch.unsqueeze(array2, 1).repeat(1, num_point1, 1),\n",
        "            (-1, num_features2))\n",
        "\n",
        "    #k=1024*1024\n",
        "    distances = (expanded_array1-expanded_array2)* (expanded_array1-expanded_array2)\n",
        "    distances = torch.sum(distances,dim=1)\n",
        "    distances = torch.reshape(distances, (num_point2, num_point1))\n",
        "    distances = torch.min(distances,dim=1)[0]\n",
        "    distances = torch.mean(distances)\n",
        "    return distances\n",
        "\n",
        "def chamfer_distance_numpy(array1, array2):\n",
        "    batch_size, num_point, num_features = array1.shape\n",
        "    dist = 0\n",
        "    cd_weight = 100\n",
        "    for i in range(batch_size):\n",
        "        av_dist1 = array2samples_distance(array1[i], array2[i])\n",
        "        av_dist2 = array2samples_distance(array2[i], array1[i])\n",
        "        dist = dist + cd_weight * (0.5*av_dist1+0.5*av_dist2)/batch_size\n",
        "    return dist\n",
        "\n",
        "class PointLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PointLoss,self).__init__()\n",
        "        \n",
        "    def forward(self,array1,array2):\n",
        "        return chamfer_distance_numpy(array1,array2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_2FiBm_a3dX"
      },
      "source": [
        "### Chamfer distance example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci77bjtGhC--"
      },
      "source": [
        "chamfer_loss = PointLoss()  # instantiate the loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRLr0rY1hb0w",
        "outputId": "80f56984-5734-4799-eca6-2650f7c23f23"
      },
      "source": [
        "print(\"Input shape: \", points.size())\n",
        "print(\"Decoded shape: \", decoded.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input shape:  torch.Size([32, 1024, 3])\n",
            "Decoded shape:  torch.Size([32, 1024, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrgYCM8IjivO",
        "outputId": "78f5baba-f821-4c06-980f-842e552e28a7"
      },
      "source": [
        "# let's compute the chamfer distance between the two sets: 'points' and 'decoded'\n",
        "loss = chamfer_loss(decoded, points)\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(27.1590, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iLLzPH5otU5",
        "outputId": "6408376a-6f2e-4d3a-833a-664f66a80d92"
      },
      "source": [
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(27.1590, device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4nO27VeayXq"
      },
      "source": [
        "## PointCloud Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0HLkZQ5amyc"
      },
      "source": [
        "def show_pointcloud(points,width=450,height=450,show_fig=True):\r\n",
        "  df = pd.DataFrame({'x':points[:, 0], 'y':points[:, 1], 'z':points[:, 2]})\r\n",
        "  df.head()\r\n",
        "  fig = px.scatter_3d(df, x='x', y='y', z='z',color='z',\r\n",
        "                       range_x=[-1,1], range_y=[-1,1], range_z=[-1,1],\r\n",
        "                      width=width, height=height)\r\n",
        "  fig.update_layout(scene_aspectmode='cube')\r\n",
        "  fig.update_traces(marker=dict(size=5),selector=dict(mode='markers'))\r\n",
        "  if show_fig==True:\r\n",
        "    fig.show()\r\n",
        "  else:\r\n",
        "    return fig\r\n",
        "\r\n",
        "\r\n",
        "def train_animation(points):\r\n",
        "  df = pd.DataFrame({'x':points[:, 0], 'y':points[:, 1], 'z':points[:, 2],'epoch':points[:,3]})\r\n",
        "  df.head()\r\n",
        "  fig = px.scatter_3d(df, x='x', y='y', z='z',color='z',animation_frame=\"epoch\",\r\n",
        "                      range_x=[-1,1], range_y=[-1,1], range_z=[-1,1],\r\n",
        "                      width=450, height=450)\r\n",
        "  fig.update_layout(scene_aspectmode='cube')\r\n",
        "  fig.update_traces(marker=dict(size=5),selector=dict(mode='markers'))\r\n",
        "  fig.show()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KEja2H88Iq1"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjW7g_K83DwN"
      },
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7Ex2VfQ28cp"
      },
      "source": [
        "blue = lambda x: '\\033[94m' + x + '\\033[0m'\r\n",
        "\r\n",
        "batchSize=12\r\n",
        "n_workers=4\r\n",
        "load_state=False    #set to True to load a saved state\r\n",
        "epoch_done=0\r\n",
        "nEpoch=30\r\n",
        "categories=['Table']\r\n",
        "LR=0.001\r\n",
        "K=20\r\n",
        "STEP_SIZE=20\r\n",
        "GAMMA=0.25\r\n",
        "ANIMATION=True\r\n",
        "\r\n",
        "model_id='100'\r\n",
        "rootFolder='/content/gdrive/MyDrive/shapenetcore_partanno_segmentation_benchmark_v0'\r\n",
        "savePath='/content/gdrive/MyDrive/PointNetAE'   #root folder for saved state of the network\r\n",
        "modelFile=savePath+'/checkpoint'+model_id+\".model\"\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFyJ9mAo28y5"
      },
      "source": [
        "### Training cycle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v3YvJRU18Mmc",
        "outputId": "b105c89a-2616-4bb5-d343-2ab6b9ef8c7c"
      },
      "source": [
        "from torch.optim.lr_scheduler import CosineAnnealingLR\r\n",
        "\r\n",
        "\r\n",
        "dataset = ShapeNetDataset(\r\n",
        "        root=rootFolder,\r\n",
        "        class_choice=categories,\r\n",
        "        classification=True,\r\n",
        "        split='train',\r\n",
        "        npoints=1024,\r\n",
        "        data_augmentation=False)\r\n",
        "\r\n",
        "\r\n",
        "val_dataset = ShapeNetDataset(\r\n",
        "        root=rootFolder,\r\n",
        "         class_choice=categories,\r\n",
        "        classification=True,\r\n",
        "        split='val',\r\n",
        "        npoints=1024,\r\n",
        "        data_augmentation=False)\r\n",
        "\r\n",
        "dataloader = torch.utils.data.DataLoader(\r\n",
        "    dataset,\r\n",
        "    batch_size=batchSize,\r\n",
        "    shuffle=True, \r\n",
        "    num_workers=n_workers)\r\n",
        "\r\n",
        "val_dataloader = torch.utils.data.DataLoader(\r\n",
        "    val_dataset,\r\n",
        "    batch_size=batchSize,\r\n",
        "    shuffle=False, \r\n",
        "    num_workers=n_workers)\r\n",
        "\r\n",
        "num_batch = len(dataset) / batchSize\r\n",
        "\r\n",
        "classifier=DGCNN_AutoEncoder(k=K)\r\n",
        "classifier.cuda() \r\n",
        "\r\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=LR, betas=(0.9, 0.999))           #alternativa a stocastic gradient descent\r\n",
        "#optimizer=optim.SGD(classifier.parameters(), lr=LR, momentum=0.9,weight_decay=1e-4)\r\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)               #Decays the learning rate of each parameter group by gamma every step_size\r\n",
        "#scheduler = CosineAnnealingLR(optimizer, nEpoch, eta_min=LR/100)\r\n",
        "    \r\n",
        "animation_points=np.empty([nEpoch*1024,4])\r\n",
        "pts=[]\r\n",
        "\r\n",
        "if load_state == True:\r\n",
        "  checkpoint = torch.load(modelFile)\r\n",
        "  epoch_done=checkpoint['epoch']\r\n",
        "  classifier.load_state_dict(checkpoint['model_state_dict'])\r\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\r\n",
        "  scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\r\n",
        "  animation_points=checkpoint['animation_points']\r\n",
        "  pts=checkpoint['pts']\r\n",
        "  print(\"loading saved state, starting from epoch:\"+str(epoch_done))\r\n",
        "\r\n",
        "\r\n",
        "for epoch in range(epoch_done,nEpoch):\r\n",
        "    total_loss=0\r\n",
        "    for i, data in enumerate(dataloader, 0):\r\n",
        "        points, target = data                                           #punti e risultato softmax\r\n",
        "        target = target[:, 0]                                           #c'è una sola classe ma è contenuta in un arraycon un solo elemento\r\n",
        "        points, target = points.cuda(), target.cuda()   \r\n",
        "        optimizer.zero_grad()                                           #resetta gradiente\r\n",
        "        classifier = classifier.train()                                 #train \r\n",
        "        decoded = classifier(points)                                    #decoded points\r\n",
        "        loss=chamfer_distance_numpy(decoded,points)\r\n",
        "        total_loss+=loss.item()\r\n",
        "        loss.backward()                                                 #calcolo gradiente\r\n",
        "        optimizer.step()\r\n",
        "        print('[%d: %d/%d] train loss: %f ' % (epoch, i, num_batch, loss.item()))\r\n",
        "\r\n",
        "        if i % 10 == 0:                                                 #ogni 10 batch\r\n",
        "            j, data = next(enumerate(val_dataloader, 0))                #prndo un singolo dato di testing\r\n",
        "            points, target = data\r\n",
        "            target = target[:, 0]\r\n",
        "            points, target = points.cuda(), target.cuda()\r\n",
        "            classifier = classifier.eval()                              #imposta il modello in modalità di validazione/testing (disattiva i batchnorm)\r\n",
        "            with torch.no_grad():\r\n",
        "              pred= classifier(points)                                   #recupera le predizioni\r\n",
        "              loss=chamfer_distance_numpy(pred,points)                           #calcola loss\r\n",
        "              print('[%d: %d/%d] %s loss: %f ' % (epoch, i, num_batch, blue('step-validation'), loss.item()))\r\n",
        "\r\n",
        "    j, data = next(enumerate(val_dataloader, 0))                #prndo un batch di dati di testing\r\n",
        "    points, target = data\r\n",
        "    target = target[:, 0]\r\n",
        "    points, target = points.cuda(), target.cuda()\r\n",
        "    pred= classifier(points)                                   #recupera le predizioni\r\n",
        "    #animation_points[epoch:epoch+1024]=np.concatenate((pred[0].cpu().detach().numpy().reshape(-1,3),np.full((1024,1),epoch)),axis=1)\r\n",
        "    #pts.append((epoch,loss.item()))\r\n",
        "    pts.append((epoch,total_loss/num_batch))\r\n",
        "    \r\n",
        "    if ANIMATION:\r\n",
        "      temp=pred[0].cpu().detach().numpy().reshape(-1,3)\r\n",
        "      for i in range(0,1024):\r\n",
        "        animation_points[epoch*1024+i]=(temp[i,0],temp[i,1],temp[i,2],epoch)\r\n",
        "    \r\n",
        "    scheduler.step() \r\n",
        "    print(\"saving parameter\")\r\n",
        "    torch.save({\r\n",
        "            'epoch': epoch+1,\r\n",
        "            'model_state_dict': classifier.state_dict(),\r\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\r\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\r\n",
        "            'animation_points': animation_points,\r\n",
        "            'pts':pts,\r\n",
        "    }, modelFile)\r\n",
        "    print(\"parameter saved\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DGCN AE Init - num_points (# generated): 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-78d2c10b50fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0mepoch_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m   \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scheduler_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1052\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1053\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DGCNN_AutoEncoder:\n\tMissing key(s) in state_dict: \"encoder.0.bn4.weight\", \"encoder.0.bn4.bias\", \"encoder.0.bn4.running_mean\", \"encoder.0.bn4.running_var\", \"encoder.0.bn5.weight\", \"encoder.0.bn5.bias\", \"encoder.0.bn5.running_mean\", \"encoder.0.bn5.running_var\", \"encoder.0.conv1.0.weight\", \"encoder.0.conv1.1.weight\", \"encoder.0.conv1.1.bias\", \"encoder.0.conv1.1.running_mean\", \"encoder.0.conv1.1.running_var\", \"encoder.0.conv2.0.weight\", \"encoder.0.conv2.1.weight\", \"encoder.0.conv2.1.bias\", \"encoder.0.conv2.1.running_mean\", \"encoder.0.conv2.1.running_var\", \"encoder.0.conv3.0.weight\", \"encoder.0.conv3.1.weight\", \"encoder.0.conv3.1.bias\", \"encoder.0.conv3.1.running_mean\", \"encoder.0.conv3.1.running_var\", \"encoder.0.conv4.0.weight\", \"encoder.0.conv4.1.weight\", \"encoder.0.conv4.1.bias\", \"encoder.0.conv4.1.running_mean\", \"encoder.0.conv4.1.running_var\", \"encoder.0.conv5.0.weight\", \"encoder.0.conv5.1.weight\", \"encoder.0.conv5.1.bias\", \"encoder.0.conv5.1.running_mean\", \"encoder.0.conv5.1.running_var\", \"encoder.0.linear3.weight\", \"encoder.0.linear3.bias\", \"encoder.4.weight\", \"encoder.4.bias\". \n\tUnexpected key(s) in state_dict: \"encoder.0.stn.conv1.weight\", \"encoder.0.stn.conv1.bias\", \"encoder.0.stn.conv2.weight\", \"encoder.0.stn.conv2.bias\", \"encoder.0.stn.conv3.weight\", \"encoder.0.stn.conv3.bias\", \"encoder.0.stn.fc1.weight\", \"encoder.0.stn.fc1.bias\", \"encoder.0.stn.fc2.weight\", \"encoder.0.stn.fc2.bias\", \"encoder.0.stn.fc3.weight\", \"encoder.0.stn.fc3.bias\", \"encoder.0.stn.bn1.weight\", \"encoder.0.stn.bn1.bias\", \"encoder.0.stn.bn1.running_mean\", \"encoder.0.stn.bn1.running_var\", \"encoder.0.stn.bn1.num_batches_tracked\", \"encoder.0.stn.bn2.weight\", \"encoder.0.stn.bn2.bias\", \"encoder.0.stn.bn2.running_mean\", \"encoder.0.stn.bn2.running_var\", \"encoder.0.stn.bn2.num_batches_tracked\", \"encoder.0.stn.bn3.weight\", \"encoder.0.stn.bn3.bias\", \"encoder.0.stn.bn3.running_mean\", \"encoder.0.stn.bn3.running_var\", \"encoder.0.stn.bn3.num_batches_tracked\", \"encoder.0.stn.bn4.weight\", \"encoder.0.stn.bn4.bias\", \"encoder.0.stn.bn4.running_mean\", \"encoder.0.stn.bn4.running_var\", \"encoder.0.stn.bn4.num_batches_tracked\", \"encoder.0.stn.bn5.weight\", \"encoder.0.stn.bn5.bias\", \"encoder.0.stn.bn5.running_mean\", \"encoder.0.stn.bn5.running_var\", \"encoder.0.stn.bn5.num_batches_tracked\", \"encoder.0.conv1.weight\", \"encoder.0.conv1.bias\", \"encoder.0.conv2.weight\", \"encoder.0.conv2.bias\", \"encoder.0.conv3.weight\", \"encoder.0.conv3.bias\". \n\tsize mismatch for encoder.0.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.0.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.0.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.0.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder.0.bn3.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.0.bn3.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.0.bn3.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder.0.bn3.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([128])."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okpMnc7t4_7s"
      },
      "source": [
        "### Loss Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5l2DOgJ5DAR"
      },
      "source": [
        "plotpts=np.asarray(pts)\r\n",
        "df = pd.DataFrame({'epoch':plotpts[:, 0], 'CD':plotpts[:, 1]})\r\n",
        "df.head()\r\n",
        "\r\n",
        "fig=px.line(df,x='epoch',y='CD',title=\"CD Plot over epoch\")\r\n",
        "\r\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCb-fpMQuIo1"
      },
      "source": [
        "if ANIMATION:\r\n",
        "  f1=open(\"animation.txt\",\"w\")\r\n",
        "  for i in range(0,int(animation_points.size/4)):\r\n",
        "    f1.write(str(animation_points[i,0])+' ')\r\n",
        "    f1.write(str(animation_points[i,1])+' ')\r\n",
        "    f1.write(str(animation_points[i,2])+' ')\r\n",
        "    f1.write(str(animation_points[i,3])+'\\n')\r\n",
        "  f1.close() \r\n",
        "\r\n",
        "  j, data = next(enumerate(val_dataloader, 0))   \r\n",
        "  points=data[0][0].cpu().detach().numpy().reshape(-1,3)\r\n",
        "  show_pointcloud(points)\r\n",
        "  print(\"training history\")\r\n",
        "  animation = np.loadtxt(\"animation.txt\", dtype=float)\r\n",
        "  train_animation(animation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sI8v_latvEWF"
      },
      "source": [
        "##Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C42uBQWDvHFe"
      },
      "source": [
        "total_loss = 0\r\n",
        "for i,data in tqdm(enumerate(val_dataloader, 0)):       #tqdm è la progressbar (salta i dati di test già visti?)\r\n",
        "    points, target = data                               \r\n",
        "    points = points.cuda()\r\n",
        "    classifier = classifier.eval()\r\n",
        "    with torch.no_grad():\r\n",
        "      decoded= classifier(points)\r\n",
        "      loss=chamfer_distance_numpy(decoded,points) \r\n",
        "      total_loss+=loss.item()\r\n",
        "\r\n",
        "total_loss=total_loss/len(val_dataloader)\r\n",
        "\r\n",
        "print(\"\\navg Validation loss {}\".format(total_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW3puOUPEgkz"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju-LhUltElgL"
      },
      "source": [
        "test_dataset={}\r\n",
        "test_dataloader={}\r\n",
        "category_loss={}\r\n",
        "\r\n",
        "for cat in categories:\r\n",
        "  test_dataset[cat] = ShapeNetDataset(\r\n",
        "          root=rootFolder,\r\n",
        "          class_choice=[cat],\r\n",
        "          classification=True,\r\n",
        "          split='test',\r\n",
        "          npoints=1024,\r\n",
        "          data_augmentation=False)\r\n",
        "  \r\n",
        "  test_dataloader[cat] = torch.utils.data.DataLoader(\r\n",
        "    test_dataset[cat],\r\n",
        "    batch_size=batchSize,\r\n",
        "    shuffle=False, \r\n",
        "    num_workers=n_workers)\r\n",
        "  \r\n",
        "  category_loss[cat]=0.0\r\n",
        "\r\n",
        "for cat in categories:\r\n",
        "  print(\"\\ntesting on \"+cat)\r\n",
        "  for i,data in tqdm(enumerate(test_dataloader[cat], 0)):       #tqdm è la progressbar (salta i dati di test già visti?)\r\n",
        "      points, target = data                               \r\n",
        "      points = points.cuda()\r\n",
        "      classifier = classifier.eval()\r\n",
        "      with torch.no_grad():\r\n",
        "        decoded= classifier(points)\r\n",
        "        loss=chamfer_distance_numpy(decoded,points) \r\n",
        "        category_loss[cat]+=loss.item()\r\n",
        "  category_loss[cat]=category_loss[cat]/len(test_dataloader[cat])\r\n",
        "  print(\"\\nloss: \"+str(category_loss[cat]))\r\n",
        "\r\n",
        "  \r\n",
        "print(category_loss)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaymO1WrK0LB"
      },
      "source": [
        "show_example=5 #max 32\r\n",
        "\r\n",
        "i=0\r\n",
        "for cat in categories:\r\n",
        "  j, data = next(enumerate(test_dataloader[cat], 0))   \r\n",
        "  points,_ = data\r\n",
        "  points = points.cuda()\r\n",
        "  classifier = classifier.eval()\r\n",
        "  decoded= classifier(points) \r\n",
        "\r\n",
        "  for j in range (1,show_example+1):\r\n",
        "    loss=chamfer_distance_numpy(points[j].reshape(1,1024,3),decoded[j].reshape(1,1024,3))\r\n",
        "    s_points=points[j].cpu().detach().numpy()\r\n",
        "    s_decoded=decoded[j].cpu().detach().numpy()\r\n",
        "\r\n",
        "    grid = make_subplots(rows=1, cols=2,\r\n",
        "                     specs=[[{'type':'scene'},{'type':'scene'}]],\r\n",
        "                     subplot_titles=['Original','Decoded loss='+str(round(loss.item(),3 ))] )\r\n",
        "    grid.add_trace(\r\n",
        "      go.Scatter3d(x=s_points[:,0],\r\n",
        "                  y=s_points[:,1],\r\n",
        "                  z=s_points[:,2],\r\n",
        "                  mode=\"markers\", \r\n",
        "                  marker=dict(size=4,color=s_points[:,2],colorscale='Inferno'),\r\n",
        "                  ),row=1, col=1)\r\n",
        "    \r\n",
        "    grid.add_trace(\r\n",
        "      go.Scatter3d(x=s_decoded[:,0], \r\n",
        "                  y=s_decoded[:,1],\r\n",
        "                  z=s_decoded[:,2],\r\n",
        "                  mode=\"markers\",\r\n",
        "                  marker=dict(size=4,color=s_decoded[:,2],colorscale='Inferno'),\r\n",
        "                  \r\n",
        "                  ),row=1, col=2)\r\n",
        "    \r\n",
        "    grid.update_layout(height=400, width=800,showlegend=False,scene_aspectmode='cube')\r\n",
        "    grid.update_scenes(aspectmode='cube',\r\n",
        "                    xaxis = dict( range=[-1,1],),\r\n",
        "                     yaxis = dict( range=[-1,1],),\r\n",
        "                     zaxis = dict( range=[-1,1],),)\r\n",
        "    grid.show()\r\n",
        "\r\n",
        "  i=i+1\r\n",
        "\r\n",
        "\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}